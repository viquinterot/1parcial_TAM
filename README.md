# Comparaci√≥n de Regresores sobre el Ames Housing Dataset y Desarrollo Te√≥rico

## Descripci√≥n
Este repositorio contiene el notebook de Colab y los recursos necesarios para comparar el desempe√±o de nueve regresores solicitados en el punto 2 del parcial de Teor√≠a de Aprendizaje de M√°quina sobre el dataset [Ames Housing Dataset](https://www.kaggle.com/datasets/shashanknecrothapa/ames-housing-dataset) utilizando:

- **Validaci√≥n cruzada** de 5 folds
- **LinearRegresor**,**Lasso**,**ElasticNet**,**KernelRidge**,**SGDRegressor**,**BayesianRidge**,**Gaussian Process Regressor**, **RandomForestRegressor**, **Support Vector Machines Regressor**  
- **Grid Search**, **Randomized Search** y **Optimizaci√≥n Bayesiana** (Optuna)  
- M√©tricas de desempe√±o: MAE, MSE, R¬≤ y MAPE  

El objetivo es identificar el modelo y la estrategia de ajuste de hiperpar√°metros que ofrezca el mejor compromiso entre sesgo y varianza en la predicci√≥n del precio de venta de viviendas en Ames, Iowa.

Se incluye Dashboard hecho en streamlit.

---

## Estructura del Repositorio

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ parcial pcm.pdf       #Desarrollo te√≥rico punto 1.
‚îú‚îÄ‚îÄ AmesHousing.csv              # Datos originales (no versionados)
‚îú‚îÄ‚îÄ Parcial.ipynb           # notebook Colab de an√°lisis (punto 2 y 3 del parcial)
‚îú‚îÄ‚îÄ gp.py
‚îú‚îÄ‚îÄ ames_cache_colab/            # Carpeta de cach√© de resultados y tablas finales
‚îÇ   ‚îî‚îÄ‚îÄ df_final_results_colab.csv

```

---

## Instalaci√≥n

1. **Clonar el repositorio**  
   ```bash
   git clone https://github.com/viquinterot/1parcial_TAM.git
   cd 1parcial_TAM
   ```

2. **Crear un entorno virtual** (recomendado)  
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Instalar dependencias**  
   ```bash
   pip install -r requirements.txt
   ```

---

## Datos

Descarga manualmente el conjunto de datos desde Kaggle y col√≥calo en la ra√≠z del repositorio con el nombre `AmesHousing.csv`. El notebook `parcial.ipynb` espera encontrarlo all√≠.

---

## Uso

### 1. An√°lisis y ajuste de modelos

Ejecuta el notebook para:

- Preprocesar los datos (imputaci√≥n, escalado, codificaci√≥n ordinal y one-hot, agrupaci√≥n de categor√≠as raras, transformaci√≥n logar√≠tmica de la variable objetivo).  
- Definir pipelines y espacios de hiperpar√°metros para cada modelo.  
- Encontrar los mejores hiperpar√°metros con Grid Search, Randomized Search y Optuna.  
- Evaluar todos los modelos con validaci√≥n cruzada externa de 5 folds y exportar resultados.

```bash
Parcial.ipynb
```

Al finalizar, encontrar√°s en `ames_cache_colab/df_final_results_colab.csv` la tabla con:

| Model                  | TuningMethod      | MAE_log_mean | MSE_log_mean | R2_log_mean | MAPE_orig_mean | ‚Ä¶ |
|:-----------------------|:------------------|:------------:|:------------:|:-----------:|:--------------:|:--|
| RandomForestRegressor  | BayesOpt_Optuna   |     0.0245   |     0.0012   |    0.9123   |     7.56 %     | ‚Ä¶ |
| ‚Ä¶                      | ‚Ä¶                 |     ‚Ä¶        |     ‚Ä¶        |    ‚Ä¶        |     ‚Ä¶          | ‚Ä¶ |

---

### 2. Dashboard interactivo (Streamlit)

Para explorar los datos y comparar los tres mejores regresores:

```bash
cd streamlit_dashboard
streamlit run 0_üëã_Hello.py
```

El dashboard incluye:

- **P√°gina de Bienvenida**: Introducci√≥n al proyecto.  
- **EDA**: Visualizaciones interactivas de distribuci√≥n, correlaciones y estad√≠sticas descriptivas.  
- **Comparaci√≥n de Modelos**: Tabla y gr√°ficos de las m√©tricas para los top-3 modelos seg√∫n MSE logar√≠tmico.

---

## Modelos y Hiperpar√°metros

| Modelo                          | Hiperpar√°metros clave                                      | B√∫squeda                          |
|:--------------------------------|:---------------------------------------------------------:|:---------------------------------:|
| **LinearRegression**            | ‚Äì                                                         | Baseline (sin ajuste)             |
| **Lasso**                       | Œ± ‚àà [5e-5, 1e-3]                                           | Grid / Random / BayesOpt          |
| **ElasticNet**                  | Œ± ‚àà [5e-4, 5e-3], l1_ratio ‚àà [0.1, 0.9]                    | Grid / Random / BayesOpt          |
| **KernelRidge**                 | Œ± ‚àà [0.1, 1.0], Œ≥ ‚àà [0.05, 0.5]                             | Grid / Random / BayesOpt          |
| **SGDRegressor**                | Œ± ‚àà [1e-5, 1e-3], penalty ‚àà {l2, elasticnet}              | Grid / Random / BayesOpt          |
| **BayesianRidge**               | Œ±_1, Œ±_2, Œª_1, Œª_2 ‚àà [1e-7, 1e-5]                          | Grid / Random / BayesOpt          |
| **GaussianProcessRegressor**    | Œ± ‚àà [0.1, 1.0]                                            | Grid / Random / BayesOpt          |
| **RandomForestRegressor**       | n_estimators ‚àà [80, 300], max_depth ‚àà [10, 50]             | Grid / Random / BayesOpt          |
| **SVR**                         | C ‚àà [1, 50], Œ≥ ‚àà [1e-3, 1.0], Œµ ‚àà [0.05, 0.2]              | Grid / Random / BayesOpt          |

Cada estrategia de b√∫squeda est√° justificada en el script (rangos seleccionados seg√∫n sensibilidad al overfitting y coste computacional) y utiliza como funci√≥n objetivo la maximizaci√≥n del **neg_mean_squared_error**.

---

## Preprocesamiento

1. **Transformaci√≥n de `SalePrice`**: log(1 + precio) para aproximaci√≥n gaussiana.  
2. **Imputaci√≥n**: mediana en num√©ricas, constante (‚ÄòMissing‚Äô / ‚ÄòMissing_Nominal‚Äô) en categ√≥ricas.  
3. **Escalado**: RobustScaler en num√©ricas.  
4. **Codificaci√≥n**:  
   - **OrdinalEncoder** en variables con orden natural (calidad, estado, exposici√≥n).  
   - **OneHotEncoder** (drop='first') en nominales.  
5. **Agrupaci√≥n de categor√≠as raras** (<1 %) a ‚ÄúRare_Category‚Äù para evitar alta dimensionalidad.

---

## M√©tricas de Evaluaci√≥n

- **MAE** (Error Absoluto Medio)  
- **MSE** (Error Cuadr√°tico Medio)  
- **R¬≤** (Coeficiente de Determinaci√≥n)  
- **MAPE** (Error Porcentual Absoluto Medio)  

Se reportan medias y desviaciones est√°ndar sobre los 5 folds de validaci√≥n externa.

Se agrega script adicional en python gp.py donde se intent√≥ mejorar la performance para Gaussian Process Regressor, disminuyendo las dimensiones de los datos con TargetEncoder y usando la estrateg√≠a de la mediana. Se usaron kernel C, RBF y WhiteKernel y tuneando alpha externamente. 

Se obtuvieron estos resultados: 

Tabla de Resultados GPR (ordenada por mejor MSE_log_mean):
                      Model     TuningMethod  MAE_log_mean  MAE_log_std  MSE_log_mean  MSE_log_std  R2_log_mean  R2_log_std  MAPE_orig_mean  MAPE_orig_std
0  GaussianProcessRegressor       GridSearch        0.1161       0.0069        0.0365       0.0065       0.7804      0.0262         12.1169         0.9401
1  GaussianProcessRegressor     RandomSearch        0.1179       0.0067        0.0375       0.0061       0.7739      0.0243         12.2724         0.9285
2  GaussianProcessRegressor  BayesOpt_Optuna        0.1190       0.0187        0.0405       0.0106       0.7581      0.0478         12.9214         1.7734

---

## Referencias

- Ames Housing Dataset (Kaggle)  
- [scikit-learn documentation](https://scikit-learn.org/)  
- [Optuna: A hyperparameter optimization framework](https://optuna.org/)  
- [Streamlit: Python framework para dashboards](https://streamlit.io/)
