# ComparaciÃ³n de Regresores sobre el Ames Housing Dataset

## DescripciÃ³n
Este repositorio contiene el notebook de Colab y los recursos necesarios para comparar el desempeÃ±o de nueve regresores solicitados en el punto 2 del parcial de TeorÃ­a de Aprendizaje de MÃ¡quina sobre el dataset [Ames Housing Dataset](https://www.kaggle.com/datasets/shashanknecrothapa/ames-housing-dataset) utilizando:

- **ValidaciÃ³n cruzada** de 5 folds
- **LinearRegresor**,**Lasso**,**ElasticNet**,**KernelRidge**,**SGDRegressor**,**BayesianRidge**,**Gaussian Process Regressor**, **RandomForestRegressor**, **Support Vector Machines Regressor**  
- **Grid Search**, **Randomized Search** y **OptimizaciÃ³n Bayesiana** (Optuna)  
- MÃ©tricas de desempeÃ±o: MAE, MSE, RÂ² y MAPE  

El objetivo es identificar el modelo y la estrategia de ajuste de hiperparÃ¡metros que ofrezca el mejor compromiso entre sesgo y varianza en la predicciÃ³n del precio de venta de viviendas en Ames, Iowa.

Se incluye Dashboard hecho en streamlit.

---

## Estructura del Repositorio

```
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ AmesHousing.csv              # Datos originales (no versionados)
â”œâ”€â”€ parcial.ipynb            # notebook Colab de anÃ¡lisis (punto 2 y 3 del parcial)
â”œâ”€â”€ ames_cache_colab/            # Carpeta de cachÃ© de resultados y tablas finales
â”‚   â””â”€â”€ df_final_results_colab.csv
â””â”€â”€ streamlit_dashboard/         # Dashboard Streamlit (punto 3 del parcial)
    â”œâ”€â”€ 0_ðŸ‘‹_Hello.py
    â””â”€â”€ pages
        â”œâ”€â”€ 1_EDA.py
        â””â”€â”€ 2_Model_Comparison.py
```

---

## InstalaciÃ³n

1. **Clonar el repositorio**  
   ```bash
   git clone https://github.com/viquinterot/1parcial_TAM.git
   cd 1parcial_TAM
   ```

2. **Crear un entorno virtual** (recomendado)  
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

3. **Instalar dependencias**  
   ```bash
   pip install -r requirements.txt
   ```

---

## Datos

Descarga manualmente el conjunto de datos desde Kaggle y colÃ³calo en la raÃ­z del repositorio con el nombre `AmesHousing.csv`. El notebook `parcial.ipynb` espera encontrarlo allÃ­.

---

## Uso

### 1. AnÃ¡lisis y ajuste de modelos

Ejecuta el notebook para:

- Preprocesar los datos (imputaciÃ³n, escalado, codificaciÃ³n ordinal y one-hot, agrupaciÃ³n de categorÃ­as raras, transformaciÃ³n logarÃ­tmica de la variable objetivo).  
- Definir pipelines y espacios de hiperparÃ¡metros para cada modelo.  
- Encontrar los mejores hiperparÃ¡metros con Grid Search, Randomized Search y Optuna.  
- Evaluar todos los modelos con validaciÃ³n cruzada externa de 5 folds y exportar resultados.

```bash
python parcial_python.py
```

Al finalizar, encontrarÃ¡s en `ames_cache_colab/df_final_results_colab.csv` la tabla con:

| Model                  | TuningMethod      | MAE_log_mean | MSE_log_mean | R2_log_mean | MAPE_orig_mean | â€¦ |
|:-----------------------|:------------------|:------------:|:------------:|:-----------:|:--------------:|:--|
| RandomForestRegressor  | BayesOpt_Optuna   |     0.0245   |     0.0012   |    0.9123   |     7.56 %     | â€¦ |
| â€¦                      | â€¦                 |     â€¦        |     â€¦        |    â€¦        |     â€¦          | â€¦ |

---

### 2. Dashboard interactivo (Streamlit)

Para explorar los datos y comparar los tres mejores regresores:

```bash
cd streamlit_dashboard
streamlit run 0_ðŸ‘‹_Hello.py
```

El dashboard incluye:

- **PÃ¡gina de Bienvenida**: IntroducciÃ³n al proyecto.  
- **EDA**: Visualizaciones interactivas de distribuciÃ³n, correlaciones y estadÃ­sticas descriptivas.  
- **ComparaciÃ³n de Modelos**: Tabla y grÃ¡ficos de las mÃ©tricas para los top-3 modelos segÃºn MSE logarÃ­tmico.

---

## Modelos y HiperparÃ¡metros

| Modelo                          | HiperparÃ¡metros clave                                      | BÃºsqueda                          |
|:--------------------------------|:---------------------------------------------------------:|:---------------------------------:|
| **LinearRegression**            | â€“                                                         | Baseline (sin ajuste)             |
| **Lasso**                       | Î± âˆˆ [5e-5, 1e-3]                                           | Grid / Random / BayesOpt          |
| **ElasticNet**                  | Î± âˆˆ [5e-4, 5e-3], l1_ratio âˆˆ [0.1, 0.9]                    | Grid / Random / BayesOpt          |
| **KernelRidge**                 | Î± âˆˆ [0.1, 1.0], Î³ âˆˆ [0.05, 0.5]                             | Grid / Random / BayesOpt          |
| **SGDRegressor**                | Î± âˆˆ [1e-5, 1e-3], penalty âˆˆ {l2, elasticnet}              | Grid / Random / BayesOpt          |
| **BayesianRidge**               | Î±_1, Î±_2, Î»_1, Î»_2 âˆˆ [1e-7, 1e-5]                          | Grid / Random / BayesOpt          |
| **GaussianProcessRegressor**    | Î± âˆˆ [0.1, 1.0]                                            | Grid / Random / BayesOpt          |
| **RandomForestRegressor**       | n_estimators âˆˆ [80, 300], max_depth âˆˆ [10, 50]             | Grid / Random / BayesOpt          |
| **SVR**                         | C âˆˆ [1, 50], Î³ âˆˆ [1e-3, 1.0], Îµ âˆˆ [0.05, 0.2]              | Grid / Random / BayesOpt          |

Cada estrategia de bÃºsqueda estÃ¡ justificada en el script (rangos seleccionados segÃºn sensibilidad al overfitting y coste computacional) y utiliza como funciÃ³n objetivo la maximizaciÃ³n del **neg_mean_squared_error**.

---

## Preprocesamiento

1. **TransformaciÃ³n de `SalePrice`**: log(1 + precio) para aproximaciÃ³n gaussiana.  
2. **ImputaciÃ³n**: mediana en numÃ©ricas, constante (â€˜Missingâ€™ / â€˜Missing_Nominalâ€™) en categÃ³ricas.  
3. **Escalado**: RobustScaler en numÃ©ricas.  
4. **CodificaciÃ³n**:  
   - **OrdinalEncoder** en variables con orden natural (calidad, estado, exposiciÃ³n).  
   - **OneHotEncoder** (drop='first') en nominales.  
5. **AgrupaciÃ³n de categorÃ­as raras** (<1 %) a â€œRare_Categoryâ€ para evitar alta dimensionalidad.

---

## MÃ©tricas de EvaluaciÃ³n

- **MAE** (Error Absoluto Medio)  
- **MSE** (Error CuadrÃ¡tico Medio)  
- **RÂ²** (Coeficiente de DeterminaciÃ³n)  
- **MAPE** (Error Porcentual Absoluto Medio)  

Se reportan medias y desviaciones estÃ¡ndar sobre los 5 folds de validaciÃ³n externa.

Se agrega script adicional en python gp.py donde se intentÃ³ mejorar la performance para Gaussian Process Regressor, disminuyendo las dimensiones de los datos con TargetEncoder y usando la estrategÃ­a de la mediana. Se usaron kernel C, RBF y WhiteKernel y tuneando alpha externamente. 

Se obtuvieron estos resultados: 

Tabla de Resultados GPR (ordenada por mejor MSE_log_mean):
                      Model     TuningMethod  MAE_log_mean  MAE_log_std  MSE_log_mean  MSE_log_std  R2_log_mean  R2_log_std  MAPE_orig_mean  MAPE_orig_std
0  GaussianProcessRegressor       GridSearch        0.1161       0.0069        0.0365       0.0065       0.7804      0.0262         12.1169         0.9401
1  GaussianProcessRegressor     RandomSearch        0.1179       0.0067        0.0375       0.0061       0.7739      0.0243         12.2724         0.9285
2  GaussianProcessRegressor  BayesOpt_Optuna        0.1190       0.0187        0.0405       0.0106       0.7581      0.0478         12.9214         1.7734

---

## Referencias

- Ames Housing Dataset (Kaggle)  
- [scikit-learn documentation](https://scikit-learn.org/)  
- [Optuna: A hyperparameter optimization framework](https://optuna.org/)  
- [Streamlit: Python framework para dashboards](https://streamlit.io/)
